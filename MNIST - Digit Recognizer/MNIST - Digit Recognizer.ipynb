{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df9577e",
   "metadata": {},
   "source": [
    "# MNIST - Digit Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0bddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Each image from the MNIST Dataset has 28x28px (784 pixels) or a problem with inputs from 0 to 255\n",
    "# 2. 0 corresponds to purely black and 255 to purely white\n",
    "# 3. We will use a SoftMax activation function for the output layer (Softmax classifiers give us the \n",
    "# probabilities for each class label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e6b65",
   "metadata": {},
   "source": [
    "## The action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61253a4e",
   "metadata": {},
   "source": [
    "#### 1. Prepare our data and preprocess it. We will create training, validation and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f033e49",
   "metadata": {},
   "source": [
    "#### 2. Outline the model and choose the activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aeb9e9",
   "metadata": {},
   "source": [
    "#### 3. Set the appropiate advanced optimizers and the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d060cf",
   "metadata": {},
   "source": [
    "#### 4. Make it learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbba8f0",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed63f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Collection of datasets ready-to-use \n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f0988",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a77b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_info parameter will provide us the version, number of samples etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f0f598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "# Splitting the dataset into train and test\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "# Extracting 10% from the training data to form the validaton dataset\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# The tf.cast() function is used to cast a specified Tensor to a  new data type.\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "# We are scaling our inputs\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.   # Dot means float number\n",
    "    return image, label\n",
    "\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# Used to shuffle the data\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "# We are Forward Propagating here\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n",
    "# iter created an object which can be iterated one element at a time (like for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbfc8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(10000, 28, 28, 1), dtype=float32, numpy=\n",
       "  array([[[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       "  \n",
       "  \n",
       "         [[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       "  \n",
       "          [[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(10000,), dtype=int64, numpy=array([2, 0, 4, ..., 8, 0, 5], dtype=int64)>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test_data = list(test_data)\n",
    "list_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size is a number of samples processed before the model is updated.\n",
    "# 1. batch size = 1 = Stochastic gradient descent(SGD)\n",
    "# 2. batch size = samples = (single batch) GD\n",
    "# 3. Mini-Batch Gradient Descent. 1 < Batch Size < Size of Training Set. \n",
    "\n",
    "# The number of epochs is the number of complete passes through the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e19933",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a77f41",
   "metadata": {},
   "source": [
    "## Outline the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1c48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 784 inputs layers\n",
    "# 10 outputs nodes for each digit\n",
    "# we will work with 2 hidden layers with 50 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbda8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 100\n",
    "\n",
    "# Flatten --> Trannsforms the tensor, the image into a vector\n",
    "# Stack the layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    # Further, we will build the neural network\n",
    "    # Takes the inputs, calculates the dot product, weights and adds the bias\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax'), # The output will be based on probabilities\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46e0d4",
   "metadata": {},
   "source": [
    "## Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32aaf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models.\n",
    "# Categorical crossentropy with integer targets = sparse_categorical_crossentropy.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdfd16",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e82e5514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 6s - loss: 0.3360 - accuracy: 0.9042 - val_loss: 0.1663 - val_accuracy: 0.9520\n",
      "Epoch 2/5\n",
      "540/540 - 3s - loss: 0.1386 - accuracy: 0.9589 - val_loss: 0.1085 - val_accuracy: 0.9687\n",
      "Epoch 3/5\n",
      "540/540 - 4s - loss: 0.0974 - accuracy: 0.9710 - val_loss: 0.0815 - val_accuracy: 0.9762\n",
      "Epoch 4/5\n",
      "540/540 - 4s - loss: 0.0740 - accuracy: 0.9776 - val_loss: 0.0740 - val_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0545 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247294d6940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# At the beggining of each epoch(iteration), the training loss will be set to zero\n",
    "# The algorithm will iterate over a preset number of batches, all from train_data\n",
    "# The weights and biases will be updated as many times as there are batches\n",
    "# We will get a value for the loss function, indicating how the training is going\n",
    "# We will also see a training accuracy\n",
    "# At the end of the epoch, the algorithm will forward propagate the whole validation set\n",
    "# Max num of epochs = training over\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705da6a8",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a32404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0815 - accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b465f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0815. Test accuracy: 97.38%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {round(test_loss, 4)}. Test accuracy: {round(test_accuracy, 4)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c18a06",
   "metadata": {},
   "source": [
    "## Testing with our own digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bba01a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "own_data = cv2.imread('numbers/six.PNG', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5279979",
   "metadata": {},
   "outputs": [],
   "source": [
    "own_data = cv2.resize(own_data, (28, 28))\n",
    "own_data = own_data.astype('float32')\n",
    "own_data = own_data.reshape(1, 28, 28, 1)\n",
    "own_data = 255-own_data\n",
    "own_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f4b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(own_data.reshape(28, 28),cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10ca6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_prediction = model.predict(own_data)\n",
    "# img_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5760b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(own_data.reshape(1, 28, 28, 1), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc128b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(pred.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
